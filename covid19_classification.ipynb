{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumbel Ijaz, PhDEE19003 Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining All Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vgg_FC_Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= 'C:/Users/840 g3/Desktop/Assignment 5 Dataset-20200421T135811Z-002/Assignment 5 Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(0),\n",
    "                                       transforms.RandomResizedCrop(1024),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(1024),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(1024),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "#pass transform here-in\n",
    "train_data = datasets.ImageFolder(root= \"/content/gdrive/My Drive/Assignment_5_Dataset/train\", transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(root= \"/content/gdrive/My Drive/Assignment_5_Dataset/test\", transform=test_transforms)\n",
    "val_data = datasets.ImageFolder(root= \"/content/gdrive/My Drive/Assignment_5_Dataset/validation\", transform=val_transforms)\n",
    "#train_data = datasets.ImageFolder(data_dir + '/train-set', transform=train_transforms)\n",
    "#test_data = datasets.ImageFolder(data_dir + '/val-set', transform=test_transforms)\n",
    "\n",
    "#data loaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size=8, shuffle=True)\n",
    "                                          \n",
    "print(\"Classes: \")\n",
    "class_names = train_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def show_databatch(inputs, classes):\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(trainloader))\n",
    "show_databatch(inputs, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model from pytorch\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "print(vgg16)\n",
    "print('Output Layer of VGG16 : ', vgg16.classifier[6].out_features) # 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = vgg16.classifier[0].in_features\n",
    "features = list(vgg16.classifier.children())[:-7] # Remove last layer\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze training for all layers\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.extend([nn.Linear(num_features, 130)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.extend([nn.Linear(130, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.classifier = nn.Sequential(*features)\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg16.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#if you have gpu then you need to convert the network and data to cuda\n",
    "#the easiest way is to first check for device and then convert network and data to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg16.to(device)\n",
    "\n",
    "vgg16.train()\n",
    "\n",
    "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
    "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "        # This is convenient while training RNNs. \n",
    "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = vgg16(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "        \n",
    "    torch.save(vgg16.state_dict(), 'vgg16_ft.pth')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "\n",
    "print('Accuracy of the network on Training images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix Part\n",
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(trainloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = vgg16(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "show_databatch(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
    "outputs = vgg16(images)                               #--> forward pass\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
    "                              for j in range(len(images))))\n",
    "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
    "                              for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "acc=[]\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "        \n",
    "\n",
    "print('Accuracy of the network on test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = vgg16(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(valloader)\n",
    "images, labels = dataiter.next()\n",
    "show_databatch(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
    "outputs = vgg16(images)                               #--> forward pass\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
    "                              for j in range(len(images))))\n",
    "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
    "                              for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "\n",
    "print('Accuracy of the network on Validation images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(valloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = vgg16(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model from pytorch\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "print(vgg16)\n",
    "print('Output Layer of VGG16 : ', vgg16.classifier[6].out_features) # 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#if you have gpu then you need to convert the network and data to cuda\n",
    "#the easiest way is to first check for device and then convert network and data to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg16.to(device)\n",
    "\n",
    "vgg16.train()\n",
    "\n",
    "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
    "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "        # This is convenient while training RNNs. \n",
    "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = vgg16(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "     from tqdm import tqdm\n",
    "\n",
    "#if you have gpu then you need to convert the network and data to cuda\n",
    "#the easiest way is to first check for device and then convert network and data to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg16.to(device)\n",
    "\n",
    "vgg16.train()\n",
    "\n",
    "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
    "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "        # This is convenient while training RNNs. \n",
    "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = vgg16(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "\n",
    "        \n",
    "    torch.save(vgg16.state_dict(), 'vgg16_ft.pth')\n",
    "\n",
    "print('Finished Training')\n",
    "#epocharray=range(0,Epochs)\n",
    "plt.plot(epoch,loss.data)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "    from tqdm import tqdm\n",
    "\n",
    "#if you have gpu then you need to convert the network and data to cuda\n",
    "#the easiest way is to first check for device and then convert network and data to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg16.to(device)\n",
    "\n",
    "vgg16.train()\n",
    "\n",
    "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
    "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "        # This is convenient while training RNNs. \n",
    "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = vgg16(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "\n",
    "        \n",
    "    torch.save(vgg16.state_dict(), 'vgg16_ft.pth')\n",
    "\n",
    "print('Finished Training')\n",
    "#epocharray=range(0,Epochs)\n",
    "plt.plot(epoch,loss.data)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "           'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "\n",
    "        \n",
    "    torch.save(vgg16.state_dict(), 'vgg16_ft.pth')\n",
    "\n",
    "print('Finished Training')\n",
    "#epocharray=range(0,Epochs)\n",
    "plt.plot(epoch,loss.data)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "\n",
    "print('Accuracy of the network on Training images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix part\n",
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(trainloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = vgg16(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "show_databatch(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
    "outputs = vgg16(images)                               #--> forward pass\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
    "                              for j in range(len(images))))\n",
    "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
    "                              for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "acc=[]\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "        \n",
    "\n",
    "print('Accuracy of the network on test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = vgg16(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(valloader)\n",
    "images, labels = dataiter.next()\n",
    "show_databatch(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
    "outputs = vgg16(images)                               #--> forward pass\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
    "                              for j in range(len(images))))\n",
    "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
    "                              for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "\n",
    "print('Accuracy of the network on Validation images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(valloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = vgg16(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet FC Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model from pytorch\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "print(resnet18)\n",
    "print('Output Layer of RESNET18 : ', resnet18.fc.out_features) # 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing the layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze training for all layers\n",
    "for param in resnet18.layer1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet18.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#if you have gpu then you need to convert the network and data to cuda\n",
    "#the easiest way is to first check for device and then convert network and data to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18.to(device)\n",
    "\n",
    "resnet18.train()\n",
    "\n",
    "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
    "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "        # This is convenient while training RNNs. \n",
    "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet18(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "        \n",
    "    torch.save(resnet18.state_dict(), 'resnet18_ft.pth')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet18(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "\n",
    "print('Accuracy of the network on Training images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix part\n",
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(trainloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = resnet18(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "show_databatch(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
    "outputs = resnet18(images)                               #--> forward pass\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
    "                              for j in range(len(images))))\n",
    "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
    "                              for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "acc=[]\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet18(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "        \n",
    "\n",
    "print('Accuracy of the network on test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = resnet18(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter1 = iter(valloader)\n",
    "images, labels = dataiter1.next()\n",
    "show_databatch(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
    "outputs = resnet18(images)                               #--> forward pass\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
    "                              for j in range(len(images))))\n",
    "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
    "                              for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet18(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "\n",
    "print('Accuracy of the network on Validation images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(valloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = resnet18(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet18 Entire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#if you have gpu then you need to convert the network and data to cuda\n",
    "#the easiest way is to first check for device and then convert network and data to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18.to(device)\n",
    "\n",
    "resnet18.train()\n",
    "\n",
    "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
    "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "        # This is convenient while training RNNs. \n",
    "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet18(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "     from tqdm import tqdm\n",
    "\n",
    "#if you have gpu then you need to convert the network and data to cuda\n",
    "#the easiest way is to first check for device and then convert network and data to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18.to(device)\n",
    "\n",
    "resnet18.train()\n",
    "\n",
    "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
    "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "        # This is convenient while training RNNs. \n",
    "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet18(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "\n",
    "        \n",
    "    torch.save(resnet18.state_dict(), 'resnet18_ft.pth')\n",
    "\n",
    "print('Finished Training')\n",
    "#epocharray=range(0,Epochs)\n",
    "plt.plot(epoch,loss.data)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "    from tqdm import tqdm\n",
    "\n",
    "#if you have gpu then you need to convert the network and data to cuda\n",
    "#the easiest way is to first check for device and then convert network and data to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18.to(device)\n",
    "\n",
    "resnet18.train()\n",
    "\n",
    "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
    "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "        # This is convenient while training RNNs. \n",
    "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet18(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "\n",
    "        \n",
    "    torch.save(resnet18.state_dict(), 'resnet18_ft.pth')\n",
    "\n",
    "print('Finished Training')\n",
    "#epocharray=range(0,Epochs)\n",
    "plt.plot(epoch,loss.data)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "           'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "\n",
    "        \n",
    "    torch.save(resnet18.state_dict(), 'resnet18_ft.pth')\n",
    "\n",
    "print('Finished Training')\n",
    "#epocharray=range(0,Epochs)\n",
    "plt.plot(epoch,loss.data)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet18(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "\n",
    "print('Accuracy of the network on Training images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix part\n",
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(trainloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = resnet18(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "show_databatch(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
    "outputs = resnet18(images)                               #--> forward pass\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
    "                              for j in range(len(images))))\n",
    "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
    "                              for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "acc=[]\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet18(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "        \n",
    "\n",
    "print('Accuracy of the network on test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = resnet18(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(valloader)\n",
    "images, labels = dataiter.next()\n",
    "show_databatch(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
    "outputs = resnet18(images)                               #--> forward pass\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
    "                              for j in range(len(images))))\n",
    "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
    "                              for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for k in range(Epochs):\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet18(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc.append(100*correct/total)\n",
    "\n",
    "print('Accuracy of the network on Validation images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "epocharray=range(0,Epochs)\n",
    "plt.plot(epocharray,acc)\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(valloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = resnet18(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(classes, preds, figsize=(4,4), normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(classes, preds)\n",
    "print('F1 score: %f' % f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
